{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc1d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "     -------------------------------------- 290.4/290.4 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pypdf) (4.4.0)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fc6507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (1.23.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (2.28.1)\n",
      "Collecting langchain-core<0.2.0,>=0.1.45\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
      "     -------------------------------------- 291.3/291.3 kB 9.1 MB/s eta 0:00:00\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-win_amd64.whl (370 kB)\n",
      "     ------------------------------------- 370.7/370.7 kB 11.3 MB/s eta 0:00:00\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (1.4.39)\n",
      "Collecting langsmith<0.2.0,>=0.1.0\n",
      "  Downloading langsmith-0.1.50-py3-none-any.whl (115 kB)\n",
      "     -------------------------------------- 115.5/115.5 kB 6.6 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.4/50.4 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (22.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.4/49.4 kB ? eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.0/53.0 kB ? eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "     -------------------------------------- 409.3/409.3 kB 8.5 MB/s eta 0:00:00\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.1-cp310-none-win_amd64.whl (139 kB)\n",
      "     ---------------------------------------- 139.1/139.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.1)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting pydantic-core==2.18.2\n",
      "  Downloading pydantic_core-2.18.2-cp310-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 3.6 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "Installing collected packages: typing-extensions, tenacity, packaging, orjson, multidict, jsonpointer, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, pydantic-core, marshmallow, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain_community\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 22.0\n",
      "    Uninstalling packaging-22.0:\n",
      "      Successfully uninstalled packaging-22.0\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.45 langchain_community-0.0.34 langsmith-0.1.50 marshmallow-3.21.1 multidict-6.0.5 orjson-3.10.1 packaging-23.2 pydantic-2.7.1 pydantic-core-2.18.2 tenacity-8.2.3 typing-extensions-4.11.0 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ec6e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.28 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-text-splitters) (0.1.45)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.7.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (0.1.50)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (3.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.28.1)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.0.4)\n",
      "Installing collected packages: langchain-text-splitters\n",
      "Successfully installed langchain-text-splitters-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc3839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-1.0.2-py3-none-any.whl (28 kB)\n",
      "Collecting google-generativeai<0.6.0,>=0.5.0\n",
      "  Downloading google_generativeai-0.5.2-py3-none-any.whl (146 kB)\n",
      "     -------------------------------------- 146.8/146.8 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.1.45)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.64.1)\n",
      "Collecting google-api-core\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "     -------------------------------------- 138.3/138.3 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.7.1)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.23.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.25.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.11.0)\n",
      "Collecting google-ai-generativelanguage==0.6.2\n",
      "  Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl (664 kB)\n",
      "     -------------------------------------- 664.5/664.5 kB 8.4 MB/s eta 0:00:00\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.127.0-py2.py3-none-any.whl (12.7 MB)\n",
      "     --------------------------------------- 12.7/12.7 MB 13.9 MB/s eta 0:00:00\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.8/48.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (0.1.50)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (6.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (5.3.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.18.2)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "     -------------------------------------- 229.1/229.1 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.6)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.59.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.26.14)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.62.2-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 16.0 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, proto-plus, httplib2, grpcio, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.59.2\n",
      "    Uninstalling grpcio-1.59.2:\n",
      "      Successfully uninstalled grpcio-1.59.2\n",
      "Successfully installed google-ai-generativelanguage-0.6.2 google-api-core-2.18.0 google-api-python-client-2.127.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.2 googleapis-common-protos-1.63.0 grpcio-1.62.2 grpcio-status-1.62.2 httplib2-0.22.0 langchain-google-genai-1.0.2 proto-plus-1.23.0 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7791c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf7db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = PyPDFLoader(r\"C:\\Users\\user\\Downloads\\RAG pdf.pdf\")\n",
    "pages=df.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e7f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8beaabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 568, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "\n",
    "chunks=text_splitter.split_documents(pages)\n",
    "\n",
    "print(len(chunks))\n",
    "\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46e8ba4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Preprint.\\n\\nUnder review.\\n\\nLeave No Context Behind:\\nEfficient Infinite Context Transformers with Infini-attention\\nTsendsuren Munkhdalai, Manaal Faruqui and Siddharth Gopal\\nGoogle\\ntsendsuren@google.com\\nAbstract\\nThis work introduces an efficient method to scale Transformer-based Large\\nLanguage Models (LLMs) to infinitely long inputs with bounded memory\\nand computation.\\n\\nA key component in our proposed approach is a new at-\\ntention technique dubbed Infini-attention.', metadata={'source': 'C:\\\\Users\\\\user\\\\Downloads\\\\RAG pdf.pdf', 'page': 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0609ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=\"AIzaSyDeFmoBbE6wNDKftGcF0mowbgzhC5HjzUw\", model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bba5804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (3.10.1)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Using cached onnxruntime-1.17.3-cp310-cp310-win_amd64.whl (5.6 MB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (2.7.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting fastapi>=0.95.2\n",
      "  Using cached fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (4.66.2)\n",
      "Collecting posthog>=2.4.0\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Collecting typer>=0.9.0\n",
      "  Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (4.1.2)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (1.23.5)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (6.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (0.7.3)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Using cached tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (2.28.1)\n",
      "Collecting build>=1.0.3\n",
      "  Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromadb) (1.62.2)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\user\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting starlette<0.38.0,>=0.37.2\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2022.12.7)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.26.14)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.23.4)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.0)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Collecting opentelemetry-instrumentation==0.45b0\n",
      "  Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.6.3)\n",
      "Collecting asgiref~=3.0\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Collecting backoff>=1.10.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting rich>=10.11.0\n",
      "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-0.21.0-cp310-none-win_amd64.whl (279 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.5.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Installing collected packages: markdown-it-py, backoff, asgiref, watchfiles, uvicorn, starlette, rich, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, huggingface-hub, coloredlogs, build, typer, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.11.4\n",
      "    Uninstalling tokenizers-0.11.4:\n",
      "      Successfully uninstalled tokenizers-0.11.4\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 build-1.2.1 chromadb-0.5.0 coloredlogs-15.0.1 fastapi-0.110.2 huggingface-hub-0.22.2 kubernetes-29.0.0 markdown-it-py-3.0.0 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-sdk-1.24.0 posthog-3.5.0 rich-13.7.1 starlette-0.37.2 tokenizers-0.19.1 typer-0.12.3 uvicorn-0.29.0 watchfiles-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.24.0 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.19.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1660abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the chunks in vector store\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Embed each chunk and load it into the vector store\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# Persist the database on drive\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "707b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a Connection with the ChromaDB\n",
    "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d405b882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "# Converting CHROMA db_connection to Retriever Object\n",
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49cfc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cddef651",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # System Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a Helpful AI Bot. \n",
    "    Your task is to provide assistance based on the context given by the user. \n",
    "    Make sure your answers are relevant and helpful.\"\"\"),\n",
    "    # Human Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35fd5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"AIzaSyDeFmoBbE6wNDKftGcF0mowbgzhC5HjzUw\", model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da907f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72ade762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1abdcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Gating Score Visualization Explained\\n\\nBased on the context provided, **gating score visualization** refers to the graphical representation of the gating score (sigmoid(β)) for the compressive memory within the Infini-attention model. This visualization specifically focuses on how the gating score varies across different attention heads and layers in the model. \\n\\n**Figure 3** plays a crucial role in understanding this visualization. It showcases the distribution of gating scores, revealing two distinct types of attention heads that emerge after training:\\n\\n* **Specialized Heads:** These heads exhibit gating scores near 0 or 1, indicating a strong preference for either utilizing or bypassing the compressive memory.\\n* **Mixer Heads:** In contrast, mixer heads display gating scores close to 0.5, suggesting a more balanced approach where they combine information from both the compressive memory and the current input.\\n\\nAnalyzing the gating score visualization helps researchers understand the inner workings of the Infini-attention model and how different attention heads specialize in processing information. \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"what is gating score visualization\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d52bac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Gating Score Visualization Explained\n",
       "\n",
       "Based on the context provided, **gating score visualization** refers to the graphical representation of the gating score (sigmoid(β)) for the compressive memory within the Infini-attention model. This visualization specifically focuses on how the gating score varies across different attention heads and layers in the model. \n",
       "\n",
       "**Figure 3** plays a crucial role in understanding this visualization. It showcases the distribution of gating scores, revealing two distinct types of attention heads that emerge after training:\n",
       "\n",
       "* **Specialized Heads:** These heads exhibit gating scores near 0 or 1, indicating a strong preference for either utilizing or bypassing the compressive memory.\n",
       "* **Mixer Heads:** In contrast, mixer heads display gating scores close to 0.5, suggesting a more balanced approach where they combine information from both the compressive memory and the current input.\n",
       "\n",
       "Analyzing the gating score visualization helps researchers understand the inner workings of the Infini-attention model and how different attention heads specialize in processing information. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2fb8c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Memory Retrieval and Update in Compressive Memory Systems:\\n\\nBased on the context provided, it seems like we're discussing a specific type of memory system called **compressive memory**.  Unlike traditional memory systems (like RAM) that grow in size as more information is added, compressive memory maintains a fixed number of parameters. This means it needs to be clever about how it stores and retrieves information to remain efficient.\\n\\nHere's a breakdown of the two key processes:\\n\\n**Memory Retrieval:**\\n\\n*   **Linear Attention Mechanism:** The context mentions using a linear attention mechanism for retrieval (Shen et al., 2018). This likely means the system focuses on specific parts of the stored information that are most relevant to the current query or task. \\n*   **Katharopoulos et al. (2020):** The specific retrieval mechanism adopted is based on the work of Katharopoulos et al. (2020), chosen for its simplicity and effectiveness. Unfortunately, without further details, the exact method remains unclear. It could involve techniques like key-value lookups or similarity search within the compressed memory space.\\n\\n**Memory Update:**\\n\\n*   **Objective-Based Updating:** When new information comes in, the parameters of the compressive memory are changed. The key objective is to ensure this new information can be retrieved accurately later. \\n*   **Stable Training Techniques:** The context mentions leveraging stable training techniques from related methods. This suggests the system may learn and improve its updating process over time, becoming more efficient at storing and retrieving information.\\n\\n**Additional Considerations:**\\n\\n*   The provided text mentions the information is from preprints under review. This means the research and methods discussed may be preliminary and subject to change.\\n*   Understanding the specific details of the memory retrieval and update mechanisms would require delving deeper into the cited works (Shen et al., 2018 and Katharopoulos et al., 2020).\\n\\n**In conclusion,** compressive memory systems employ sophisticated methods for storing and retrieving information within a limited space. While the specifics mentioned in the context remain somewhat vague, they point towards the use of linear attention mechanisms and objective-driven update processes to ensure efficient information management. \\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Can you please tell me about meory retival and memory update\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32ccb36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Memory Retrieval and Update in Compressive Memory Systems:\n",
       "\n",
       "Based on the context provided, it seems like we're discussing a specific type of memory system called **compressive memory**.  Unlike traditional memory systems (like RAM) that grow in size as more information is added, compressive memory maintains a fixed number of parameters. This means it needs to be clever about how it stores and retrieves information to remain efficient.\n",
       "\n",
       "Here's a breakdown of the two key processes:\n",
       "\n",
       "**Memory Retrieval:**\n",
       "\n",
       "*   **Linear Attention Mechanism:** The context mentions using a linear attention mechanism for retrieval (Shen et al., 2018). This likely means the system focuses on specific parts of the stored information that are most relevant to the current query or task. \n",
       "*   **Katharopoulos et al. (2020):** The specific retrieval mechanism adopted is based on the work of Katharopoulos et al. (2020), chosen for its simplicity and effectiveness. Unfortunately, without further details, the exact method remains unclear. It could involve techniques like key-value lookups or similarity search within the compressed memory space.\n",
       "\n",
       "**Memory Update:**\n",
       "\n",
       "*   **Objective-Based Updating:** When new information comes in, the parameters of the compressive memory are changed. The key objective is to ensure this new information can be retrieved accurately later. \n",
       "*   **Stable Training Techniques:** The context mentions leveraging stable training techniques from related methods. This suggests the system may learn and improve its updating process over time, becoming more efficient at storing and retrieving information.\n",
       "\n",
       "**Additional Considerations:**\n",
       "\n",
       "*   The provided text mentions the information is from preprints under review. This means the research and methods discussed may be preliminary and subject to change.\n",
       "*   Understanding the specific details of the memory retrieval and update mechanisms would require delving deeper into the cited works (Shen et al., 2018 and Katharopoulos et al., 2020).\n",
       "\n",
       "**In conclusion,** compressive memory systems employ sophisticated methods for storing and retrieving information within a limited space. While the specifics mentioned in the context remain somewhat vague, they point towards the use of linear attention mechanisms and objective-driven update processes to ensure efficient information management. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049dea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
